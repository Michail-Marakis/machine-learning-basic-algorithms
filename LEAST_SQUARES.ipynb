{"cells":[{"cell_type":"markdown","metadata":{"id":"GKASc4PVh3Tb"},"source":["#LEAST SQUARES\n","Στον αλγόριθμο των ελαχίστων τετραγώνων αρχικά προσθέτουμε έναν bias όρο στα δεδομένα. Στη συνέχεια μετατρέπουμε τα labels σε one-hot μορφή, για να μπορέσουμε να χειριστούμε το πρόβλημα της ταξινόμησης σαν πρόβλημα παλινδρόμησης. Τα βάρη του μοντέλου υπολογίζονται απευθείας μέσω των normal equations, χωρίς κάποια επαναληπτική διαδικασία. Για την πρόβλεψη, υπολογίζουμε τις τιμές που αντιστοιχούν σε κάθε κλάση και επιλέγουμε εκείνη με τη μεγαλύτερη τιμή. Τέλος, αξιολογούμε το μοντέλο χρησιμοποιώντας το accuracy στο test set."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1027,"status":"ok","timestamp":1768746781372,"user":{"displayName":"mike","userId":"13144580131922358808"},"user_tz":-120},"id":"KOC4Of_Y288y","outputId":"f1a4adc0-0738-456c-cdc0-abe3dfd066cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","--- Least Squares ---\n","Train Accuracy: 1.0000\n","Test Accuracy : 1.0000\n","Train MSE Loss: 0.033128\n","Test MSE Loss: 0.038622\n"]}],"source":["import numpy as np\n","from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","import pandas as pd\n","import torch\n","drive.mount('/content/drive')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","file_path = '/content/drive/MyDrive/wine_dataset.csv'\n","\n","def add_bias(X):\n","    return np.c_[np.ones(X.shape[0]), X]\n","\n","def one_hot(y, K):\n","    Y = np.zeros((len(y), K))\n","    for i in range(len(y)):\n","        Y[i, y[i]] = 1\n","    return Y\n","\n","def fit_ls(A, Y, l=0.001):\n","    I = np.eye(A.shape[1])\n","    W = np.linalg.solve(np.dot(A.T, A) + l * I, np.dot(A.T, Y))\n","    return W\n","\n","def predict_ls(A, W):\n","    scores = np.dot(A, W)\n","    return np.argmax(scores, axis=1)\n","\n","def mse_loss(A, W, Y_true):\n","    # MSE on one-hot targets (Least Squares objective)\n","    Y_pred = np.dot(A,W)\n","    return np.mean((Y_pred - Y_true) ** 2)\n","\n","df = pd.read_csv(file_path)\n","X = df.drop('target', axis=1).values\n","y = df['target'].values\n","\n","K = len(np.unique(y))\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.25, random_state=12, stratify=y\n",")\n","\n","# add bias\n","X_train_b = add_bias(X_train)\n","X_test_b  = add_bias(X_test)\n","\n","# one-hot for training objective\n","Y_train = one_hot(y_train, K)\n","Y_test  = one_hot(y_test, K)\n","\n","# train\n","W = fit_ls(X_train_b, Y_train, l=0.001)\n","\n","# predictions\n","train_pred = predict_ls(X_train_b, W)\n","test_pred  = predict_ls(X_test_b, W)\n","\n","train_acc = (train_pred == y_train).mean()\n","test_acc  = (test_pred == y_test).mean()\n","\n","train_mse = mse_loss(X_train_b, W, Y_train)\n","test_mse  = mse_loss(X_test_b, W, Y_test)\n","\n","print(\"--- Least Squares ---\")\n","print(f\"Train Accuracy: {train_acc:.4f}\")\n","print(f\"Test Accuracy : {test_acc:.4f}\")\n","print(f\"Train MSE Loss: {train_mse:.6f}\")\n","print(f\"Test MSE Loss: {test_mse:.6f}\")\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}